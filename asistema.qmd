---
title: "Universidad de El Salvador \n\n Facultad Multidisciplinaria de Occidente \n\n\n Materia: An√°lisis de Sistema\n\n Docente: Jaime Isaac Pe√±a\n\n Pr√°ctica de Estadistica Correlaci√≥n Lineal\n Estudiante: Jacquelinne Rossibeth Guti√©rrez Figueroa. \n\n Carnet: GF19005"
format: pdf
editor: visual
jupyter: python3
---

\newpage

\tableofcontents

\newpage

# Correlaci√≥n Lineal

### Tratamiento de datos

Pandas est√° dise√±ada espec√≠ficamente¬†para la manipulaci√≥n y el an√°lisis de datos en el lenguaje Python.

```{python}

import pandas as pd
import numpy as np
from sklearn.datasets import load_diabetes
```

### Gr√°ficos

```{python}
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
```

### Procesado y an√°lisis

```{python}
import statsmodels.api as sm
```

```{python}
import pingouin as pg
```

```{python}
from scipy import stats
from scipy.stats import pearsonr
```

### Configuraci√≥n matplotlib

```{python}
plt.style.use('ggplot')
```

### Configuraci√≥n warnings

```{python}
import warnings
warnings.filterwarnings('ignore')
```

## Datos

```{python}
url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/' +
       'Estadistica-machine-learning-python/master/data/Howell1.csv')
datos = pd.read_csv(url)

# Se utilizan √∫nicamente informaci√≥n de individuos mayores de 18 a√±os.
datos = datos[datos.age > 18]

datos.info()
```

## An√°lsis Gr√°fico

En primer lugar se representan las dos variables mediante un diagrama de dispersi√≥n (*scatterplot*) para intuir si existe relaci√≥n lineal o monot√≥nica. Si no la hay, no tiene sentido calcular este tipo de correlaciones.

```{python}
# Gr√°fico
# ==============================================================================
fig, ax = plt.subplots(1, 1, figsize=(6,4))
ax.scatter(x=datos.height, y=datos.weight, alpha= 0.8)
ax.set_xlabel('Altura')
ax.set_ylabel('Peso');
```

Se puede observar un diagrama de dispersi√≥n el cual parece indicar una relaci√≥n lineal positiva entre ambas variables siendo estas variables altura y peso.

Para poder elegir el coeficiente de correlaci√≥n adecuado, se tiene que analizar el tipo de variables y la distribuci√≥n que presentan. En este caso, ambas variables son cuantitativas continuas y pueden ordenarse para convertirlas en un ranking, por lo que, a priori, los tres coeficientes podr√≠an aplicarse. La elecci√≥n se har√° en funci√≥n de la distribuci√≥n que presenten las observaciones: normalidad, homocedasticidad y presencia de¬†*outliers*

## Test de Normalidad

### Gr√°fico de distribuci√≥n de variables

```{python}
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))

axs[0].hist(x=datos.height, bins=20, color="#3182bd", alpha=0.5)
axs[0].plot(datos.height, np.full_like(datos.height, -0.01), '|k', 
markeredgewidth=1)
axs[0].set_title('Distribuci√≥n altura (height)')
axs[0].set_xlabel('height')
axs[0].set_ylabel('counts')

axs[1].hist(x=datos.weight, bins=20, color="#3182bd", alpha=0.5)
axs[1].plot(datos.weight, np.full_like(datos.weight, -0.01), '|k', 
markeredgewidth=1)
axs[1].set_title('Distribuci√≥n peso (weight)')
axs[1].set_xlabel('weight')
axs[1].set_ylabel('counts')


plt.tight_layout();
```

### Gr√°fico Q-Q

```{python}
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))

sm.qqplot(
    datos.height,
    fit   = True,
    line  = 'q',
    alpha = 0.4,
    lw    = 2,
    ax    = axs[0]
)
axs[0].set_title('Gr√°fico Q-Q height', fontsize = 10, fontweight = "bold")
axs[0].tick_params(labelsize = 7)

sm.qqplot(
    datos.height,
    fit   = True,
    line  = 'q',
    alpha = 0.4,
    lw    = 2,
    ax    = axs[1]
)
axs[1].set_title('Gr√°fico Q-Q height', fontsize = 10, fontweight = "bold")
axs[1].tick_params(labelsize = 7)
```

Adem√°s del estudio gr√°fico, se recurre a dos test estad√≠sticos que contrasten la normalidad de los datos: *Shapiro-Wilk test* y *D'Agostino's K-squared test*. Este √∫ltimo es el que incluye el *summary* de **statsmodels** bajo el nombre de *Omnibus*.

En ambos test, la hip√≥tesis nula considera que los datos siguen una distribuci√≥n normal, por lo tanto, si el *p-value* no es inferior al nivel de referencia *alpha* seleccionado, no hay evidencias para descartar que los datos se distribuyen de forma normal.

### Test de Normalidad de los residuos Shapiro-Wilk 

```{python}
shapiro_test = stats.shapiro(datos.height)
print(f"Variable height: {shapiro_test}")
shapiro_test = stats.shapiro(datos.weight)
print(f"Variable weight: {shapiro_test}")
```

### Test de Normalidad de los residuos D'Agostino's K-squared test

```{python}
k2, p_value = stats.normaltest(datos.height)
print(f"Variable height: Estad√≠tico = {k2}, p-value = {p_value}")
k2, p_value = stats.normaltest(datos.weight)
print(f"Variable weight: Estad√≠tico = {k2}, p-value = {p_value}")
```

El an√°lisis gr√°fico y los test estad√≠sticos muestran evidencias de que no se puede asumir normalidad en ninguna de las dos variables. Siendo estrictos, este hecho excluye la posibilidad de utilizar el coeficiente de Pearson, dejando como alternativas el de Spearman o Kendall. Sin embargo, dado que la distribuci√≥n no se aleja mucho de la normalidad y de que el coeficiente de Pearson tiene cierta robustez, a fines pr√°cticos s√≠ que se podr√≠a utilizar siempre y cuando se tenga en cuenta este hecho y se comunique en los resultados. Otra posibilidad es tratar de transformar las variables para mejorar su distribuci√≥n, por ejemplo, aplicando el logaritmo.

### Transformaci√≥n logar√≠tmica de los datos

```{python}
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))

sm.qqplot(
    np.log(datos.height),
    fit   = True,
    line  = 'q',
    alpha = 0.4,
    lw    = 2,
    ax    = ax
)
ax.set_title('Gr√°fico Q-Q log(height)', fontsize = 13)
ax.tick_params(labelsize = 7)


shapiro_test = stats.shapiro(np.log(datos.height))
print(f"Variable height: {shapiro_test}")
```

La trasformaci√≥n logar√≠tmica de la variable altura (*height*) consigue una distribuci√≥n m√°s pr√≥xima a la normal.

## Homocedasticidad

La homocedasticidad implica que la varianza se mantiene constante. Puede analizarse de forma gr√°fica representando las observaciones en un diagrama de dispersi√≥n y viendo si mantiene una homogeneidad en su dispersi√≥n a lo largo del eje X. Una forma c√≥nica es un claro indicativo de falta de homocedasticidad. Dos test estad√≠sticos utilizados para contrastar la homocedasticidad son: test de *Goldfeld-Quandt* y el de *Breusch-Pagan*.

Tal como muestra el diagrama de dispersi√≥n generado al inicio del ejercicio, no se aprecia ning√∫n patr√≥n c√≥nico y la dispersi√≥n es constante.

## Coeficiente de Correlaci√≥n

Debido a la falta de normalidad, los resultados generados por Pearson no son del todo precisos. Sin embargo, dado que la desviaci√≥n de la normalidad es leve y no se aprecian *outliers*, con fines ilustrativos, se procede a calcular los tres tipos de coeficientes.

De nuevo recordar que, cuando alguna de las condiciones asumidas por un modelo o test estad√≠stico no se cumplen, no significa que obligatoriamente se tenga que descartar, pero hay que ser consciente de las implicaciones que tiene y reportarlo siempre en los resultados.

#### Pandas

Pandas permite calcular la correlaci√≥n de dos Series (columnas de un DataFrame). El c√°lculo se hace por pares, eliminando autom√°ticamente aquellos con valores NA/null. Una limitaci√≥n de Pandas es que no calcula la significancia estad√≠stica.

#### C√°lculo de correlaci√≥n con pandas

```{python}
print('Correlaci√≥n Pearson: ', datos['weight'].corr(datos['height'], method='pearson'))
print('Correlaci√≥n spearman: ', datos['weight'].corr(datos['height'], method='spearman'))
print('Correlaci√≥n kendall: ', datos['weight'].corr(datos['height'], method='kendall'))
```

#### Significancia Estad√≠stica

```{python}
# C√°lculo de correlaci√≥n y significancia con Scipy
# ==============================================================================
r, p = stats.pearsonr(datos['weight'], datos['height'])
print(f"Correlaci√≥n Pearson: r={r}, p-value={p}")

r, p = stats.spearmanr(datos['weight'], datos['height'])
print(f"Correlaci√≥n Spearman: r={r}, p-value={p}")

r, p = stats.kendalltau(datos['weight'], datos['height'])
print(f"Correlaci√≥n Pearson: r={r}, p-value={p}")
```

### Conclusi√≥n 

Los test estad√≠sticos muestran una correlaci√≥n lineal entre moderada y alta, con claras evidencias estad√≠sticas de que la relaci√≥n observada no se debe al azar (pvalue‚âà0ùëùùë£ùëéùëôùë¢ùëí‚âà0).

---
documentclass: article
#title: "indices"
format: pdf
editor: visual
jupyter: python3
lang: es-ES
---

```{=tex}

\begin{titlepage}
\centering
{\bfseries\LARGE UIVERSIDAD DE EL SALVADOR FACULTAD MULTIDISCIPLINARIA DE OCCIDENTE \par}
\centering
{\includegraphics[width=0.4\textwidth]{logoues.jpg}\par}
\vspace{1cm}
\vspace{1cm}
{\scshape\Large Departamento de Matem\'atica \par}
\vspace{1cm}
{\scshape\large T\'itulo del proyecto \par}
\vspace{1cm}
{\itshape\Large\Huge Análisis multivariado aplicando componentes principales al caso de los desplazados \par}
\vfill
{\Large Autor: \par}
{\Large Mayra Cañas y Jacquelinne Gutiérrez \par}
\vfill
{\Large 03 junio de 2024 \par}
\end{titlepage}
```
\newpage

\tableofcontents

\newpage

\addcontentsline{toc}{section}{\listfigurename}

```{=tex}
\listoffigures
\newpage
```
\addcontentsline{toc}{section}{listoftables}

```{=tex}
\listoftables
\newpage
```
\section{Introducción}

La humanidad en su evolución necesita conocer los fenómenos que están a su alrededor porque éstos afectan su desarrollo dentro de todos los ámbitos (fenómenos de tipo social, económico, tecnológico, físico, etc.). Este conocimiento se logra mediante la construcción de modelos que puedan reproducir y explicar dichos fenómenos. Por tal motivo, es necesario que los profesionales, directivos e investigadores en las distintas áreas del saber estén familiarizados con las herramientas necesarias para la construcción y adecuación de modelos. Una de las herramientas más importantes para llevar a cabo este objetivo es la estadística, y en particular, muy a menudo, la estadística multivariada.

Según Peña y Dallas existen diversas definiciones acerca de las técnicas de análisis de datos multivariados, pero los dos coinciden en a conceptualizarla como "una herramienta que tiene como objetivo principal resumir grandes cantidades de datos por medio de pocos parámetros (simplificación), además busca encontrar relaciones entre:

Variables de respuesta

Unidades experimentales

Variables de respuesta y unidades experimentales

Según Peña, la mayoría de problemas que requieren la aplicación de la estadística exigen el tratamiento de muchos factores o variables y que por esto las técnicas del análisis de datos multivariados constituyen una herramienta poderosa para la toma de decisiones en las diferentes disciplinas, pues dan respuesta a necesidades palpables y plenamente identificables. Según Pérez, se puede observar que cuando existen muchas variables es posible que parte importante de la información sea redundante, en cuyo caso es necesario eliminar el exceso y dejar sólo variables que tengan representatividad dentro del conjunto. Esto se consigue con la aplicación de las técnicas multivariantes de reducción de la dimensión: análisis de componentes principales, factorial, correspondencias, escalamiento óptimo, homogeneidades, análisis conjunto.

Las técnicas multivariadas más utilizadas en el análisis de datos son: análisis de componentes principales; análisis factorial; análisis de clasificación entre los que se encuentran: discriminante, regresión logística y clúster; análisis multivariado de la varianza, y análisis de variables canónicas.

Con este artículo se desean integrar conocimientos teóricos y prácticos a través de la comprensión de las componentes principales, como una de las técnicas estadísticas que permiten estudiar la información que se dispone antes de entrar en el uso de los otros métodos que abordan el análisis de datos multivariados.

Por ser tan amplio el tema, este artículo sólo trata del análisis de componentes principales debido a su importancia dentro del desarrollo de las diversas técnicas de análisis de datos multivariados.

```{=tex}
\section{Capítulo 1}
\subsection{Componentes Principales}
```
Siguiendo a autores como Peña y Bramardi, el análisis de componentes principales (ACP) es una técnica estadística propuesta a principios del siglo XX por Hotelling (1933) quien se basó en los trabajos de Karl Pearson (1901) y en las investigaciones sobre ajustes ortogonales por mínimos cuadrados. Interpretando la definición de diversos autores, se puede decir que el ACP es una técnica estadística de análisis multivariado que permite seccionar la información contenida en un conjunto de p variables de interés en m nuevas variables independientes. Cada una explica una parte específica de la información y mediante combinación lineal de las variables originales otorgan la posibilidad de resumir la información, total en pocas componentes que reducen la dimensión del problema.

La mayor aplicación del ACP está centrada en la de reducción de la dimensión del espacio de los datos, en hacer descripciones sintéticas y en simplificar el problema que se estudia.

Para Peña, el ACP tiene una utilidad doble; por un lado, permite hacer representaciones de los datos originales en un espacio de dimensión pequeña y, por el otro, transformar las variables originales correladas en nuevas variables incorreladas que puedan ser interpretadas.

El ACP también se emplea con frecuencia cuando se desea dividir las unidades experimentales en subgrupos de acuerdo con la similaridad de los mismos. Igualmente, es útil para transformar un conjunto de variables respuesta correlacionadas en un conjunto de componentes no correlacionados, bajo el criterio de máxima variabilidad acumulada y, por tanto, de mínima pérdida de información.

Otra aplicación es el cribado, el cual permite el seguimiento sobre los componentes principales obtenidos para comprobar hipótesis establecidas en un estudio de análisis de datos multivariados y para identificar datos atípicos en el conjunto de datos.

De igual manera, García y Gil afirman que el ACP es un criterio fundamental para hacer conjeturas sobre el numero de factores que se deben determinar en el análisis factorial y para probar si, en realidad, un grupo de variables p \> 2 cae dentro de un espacio de dos o tres dimensiones que permita ser observado dentro del análisis de clúster.

Pérez anota que el análisis de componentes principales es en muchas ocasiones un paso previo a otros análisis, en los que se sustituye el conjunto de variables originales por las componentes obtenidas. Éste siempre debe hacerse cuando se quiera obtener modelos en los que sea necesario el uso de las variables originales como explicativas para tratar con algunos problemas presentes, como la independencia.

Según Gil, en el análisis discriminante cuando se tienen menos observaciones que variables y es difícil encontrar nuevas observaciones, el ACP es útil para determinar un menor número de variables que resuma la máxima variabilidad de las originales y con las cuales se pueda construir la matriz de varianza-covarianza, de tal forma que sea invertible y permita elaborar una regla de discriminación necesaria para clasificar nuevas observaciones.

Finalmente, el ACP se usa como base para determinar si ocurre multicolinealidad entre variables predictoras en el análisis de regresión múltiple. Entendiéndose como multicolinealidad cuando en dos o más variables existe redundancia; esto es, la información de una o más variables ya está explicada en otra(s) variable(s) (véase por ejemplo, Peña, Dallas).

\subsection{Notaciones y Símbolos}

Siguiendo la simbología común de diversos autores, a continuación se presentan conceptos básicos del álgebra de matrices que son necesarios en el ACP.

\subsubsection{Matriz de variable respuesta}

La base para la utilización del ACP es la estructura de correlación (interdependencia) entre las variables cuantitativas definidas en una población, en donde cada individuo queda definido en términos de las mismas. La matriz de variable respuesta de doble entrada X está compuesta por filas que representan las unidades experimentales Ir, r=1,2,....,n y las columnas, por las variables Xj, j= 1,2,...., p, como se muestra a continuación:

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen1.jpg}
\caption{Figura 1}
\end{figure}
```
\subsubsection{Vectores de datos}

Con el fin de tener un lenguaje común en los procesos de ACP, en adelante, los vectores siempre serán columnas a o X, etc., y la transpuesta de un vector cualquiera, por ejemplo a, se simboliza por a'.

\subsubsection {Vectores de medias y matrices de varianza covarianza}

La media de un vector X de variables aleatorias se denota por µ, definido por:

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen2.jpg}
\caption{Figura 2}
\end{figure}
```
La matriz de covarianza de *X* se denota por Σ, donde:

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen3.jpg}
\caption{Figura 3}
\end{figure}
```
\subsubsection {Correlación y matriz de correlación}

El coeficiente de correlación entre *X~i~* y *X~j~* se denota por:

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen4.jpg}
\caption{Figura 4}
\end{figure}
```
La matriz de evaluación para un vector aleatorio X se denota por:

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen5.jpg}
\caption{Figura 5}
\end{figure}
```
\subsubsection{Matrices ortogonales unitarias}

Dentro del álgebra de matrices las rotaciones de un espacio vectorial son transformaciones lineales del espacio vectorial sobre sí mismo y están asociadas con matrices cuadradas, unitarias y ortogonales. Una matriz de éstas, Q, tiene tantas filas y columnas como sea la dimensión del espacio. Sus columnas son vectores unitarios (es decir, de longitud igual a la unidad) y tiene la particularidad de que al ser multiplicada por su transpuesta produce la matriz unidad. En otras palabras, *Q*^-1^ = *Q*'. En cambio, las traslaciones no son transformaciones lineales pero tienen la propiedad de no modificar la variabilidad de la nube de puntos. Es decir, las varianzas y covarianzas en la nube son las mismas antes y después de una traslación. Lo expuesto anteriormente, junto con algunas propiedades de la matriz de varianzas covarianzas Σ, constituye las bases sobre las cuales descansa la técnica de componentes principales.

\section{ PLANTEAMIENTO Y SOLUCIÓN DEL PROBLEMA DE LOS COMPONENTES PRINCIPALES}

El ACP es una técnica descriptiva; sin embargo, no niega la posibilidad de que también pueda ser utilizado con fines de inferencia. Por otra parte, las aplicaciones del ACP son numerosas y entre ellas se pueden citar la clasificación de individuos, la comparación de poblaciones, la estratificación multivariada, entre otras. En el ACP se maneja un número *p* (*p* ≥ *2*) de variables numéricas. Si cada variable se representa sobre un eje, se necesitaría un sistema de coordenadas rectangulares con p ejes perpendiculares entre sí para ubicar las coordenadas de los puntos y poderlos dibujar. Cuando *p* ≥ 4, para el ser humano es imposible hacer la representación gráfica. En estos casos el ACP permite buscar un nuevo sistema de coordenadas con origen en el centro de gravedad de la nube de puntos, de tal manera que el primer eje del nuevo sistema *F~1~* recoja la mayor cantidad posible de variación; el segundo eje *F~2~*, la mayor cantidad posible entre la variación restante; el tercer eje *F~3~* la mayor cantidad posible entre la variación que queda después de las dos anteriores y así sucesivamente. Las Figuras 5 y 6 permiten ver la representación gráfica de dos componentes.

Figura 5

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen6.jpg}
\caption{Figura 6}
\end{figure}
```
Figura 6

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen7.jpg}
\caption{Figura 7}
\end{figure}
```
Cuando ya se ha definido el problema es factible abordarlo. Según Peña, páginas 73-74, la matriz de varianza covarianza Σ es definida positiva, es decir, la forma cuadrática asociada a ella tiene todas sus raíces positivas. Lo anterior hace que esta matriz tenga p valores propios reales y diferentes, lo cual garantiza que sea diagonalizable.

Una vez resuelto el problema de la rotación, bastará multiplicar la vac c c riable centrada *Xc = X - µ = ( X~1~ , X~2~ ,..., X~p~ )* por la matriz de rotación A para obtener la nueva variable, *Y = (Y~1~, Y~2~ ,... Y~p~ )* llamada variable de componentes principales. Cada componente *Y~i~* del vector aleatorio *Y* se llama una componente principal. Evidentemente se cumple que *Y~j~ = a~j1~ X~c~ + a~j2~ X~c2~ ,..., + a~jp~ X~cp~* , es decir, cada componente principal es 1 una combinación lineal de las variables originales centradas. Para hacer el análisis de los autovalores se necesita desarrollar los conceptos y las propiedades que se verifican. La traza de Σ, por ser la suma de las varianzas de las variables originales *Y~i~* recibe el nombre de varianza total, resulta claro que *traza(Σ) = traza (ADA^-1^) = Σ λ~i~*. Se puede probar además que *V(Y~i~ ) = λ~i~* para *i* = 1,2..., *p* y que *Cov(Y~i~ , Y~j~) = 0*, con *i â  j*. Esto implica varios aspectos, a saber: La varianza total es igual a la suma de los valores propios de *λ~i~* e igual a la suma de las varianzas de las componentes principales. Es decir, la varianza total es la misma con las variables originales que con las variables transformadas *Y~i~*. Las componentes principales son variables aleatorias no correlacionadas entre sí, obtenidas mediante la transformación lineal del vector de las variables originales centradas por la matriz de autovectores.

\section{UN CASO DE APLICACIÓN DEL ANÁLISIS DE COMPONENTES PRINCIPALES}

\subsection{Descripción del problema}

Según la ley 387 de 1997, "Es desplazado toda persona que se ha visto forzada a migrar dentro del territorio nacional abandonando su localidad de residencia o actividades económicas habituales, porque su vida, su integridad física, su seguridad o libertad personales han sido vulneradas o se encuentran directamente amenazadas, con ocasión de cualquiera de las siguientes situaciones: Conflicto armado interno, disturbios y tensiones interiores, violencia generalizada, violaciones masivas de los Derechos Humanos, infracciones al Derecho Internacional Humanitario u otras circunstancias emanadas de las situaciones anteriores que puedan alterar o alteren drásticamente el orden público".

Nuestro problema está basado en la lectura de la situación de los desplazados en un municipio de Colombia, donde se concentran el mayor porcentaje de estas personas que huyen de la violencia y el temor que generan las fuerzas oscuras en los campos del país.

Mediante entrevistas a expertos, a los mismos desplazados y la observación directa, se ha podido determinar problemas de diferente índole, tales como: la ubicación desordenada de los desplazados que han incomodado hasta llegar a roces con el personal que habita en los diferentes barrios, hacinamiento, inseguridad, y otros problemas de orden público.

Para analizar más profundamente esta problemática, los investigadores han recopilado información de fuentes (como, por ejemplo, el ministerio de Protección Social, el Sistema de Información de Hogares Desplazados por Violencia en Colombia - SISDES; el boletín sobre "Niños desplazados" editado por Codhes el 25 de octubre de 1997, entre otros) relativa a la población desplazada, con el propósito de contribuir desde la academia a ver técnicamente el problema con la ayuda del análisis de componentes principales.

Los datos de la Tabla 1 corresponden a la investigación exploratoria y estimaciones realizadas por los autores con el fin de encontrar los niveles de incidencia de los factores que conforman el problema de los desplazados en la comunidad.

Lo anterior se consigue mediante ACP, con lo cual se obtienen resultados útiles para ver más claro la gravedad del problema (véase resultados finales en esta sección). Para este estudio se han definido las variables que a continuación se nombran en los 25 lugares donde se ubican los desplazados: HPM: Horas promedio de movilidad diaria; NPM: Número promedio de desplazados por mes; NHS: Número de horas semanales que los centros de alimentación están en funcionamiento; ATR: Área total de recreación de uso común (en metros cuadrados); NBC: Número de centros del lugar de posible concentración; CCD: Cantidad de camas disponibles; NTC: Número total de cuartos; HHM: Horas-hombre mensual requeridas para atenderlos.

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla1.jpg}
\caption{Tabla 1}
\end{table}
```
Estos datos fueron procesados con SPSS y *Statgraphics* y se obtuvieron los resultados que aparecen a continuación, para sacar algunas conclusiones que sirven para consolidar el estudio sobre el ACP.

\subsection{Estadísticos descriptivos}

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla2.jpg}
\caption{Tabla 2}
\end{table}
```
En la Tabla 2 se muestran la media, la desviación y el coeficiente de variación para cada una de las variables (análisis univariante). Estos valores permiten estimar la variable centrada tipificada Z. El objetivo de esta tipificación es homogenizar las unidades de medidas, buscando que todas pesen por igual en el análisis como se dijo anteriormente.

\subsection{Matriz de correlaciones y prueba de independencia}

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla3.jpg}
\caption{Tabla 3}
\end{table}
```
Determinante=0,000469886

El tener determinante bajo y coeficiente de correlaciones relativamente altas entre las variables originales es un buen indicador para utilizar la técnica de componentes principales que ayuda a resumir las variables en pocas dimensiones cuando se hace este tipo de análisis. Esto se debe a que las correlaciones altas implican dependencia lineal entre las variables, dando lugar a que se puedan explicar con un número menor de variables llamadas componentes principales Yi . Todo lo anterior, y suponiendo normalidad de los datos, se puede corroborar con la prueba de independencia que se muestra en la siguiente tabla (p-valor=0 es menor que 0,05 y KMO es próximo a 1):

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla4.jpg}
\caption{Tabla 4}
\end{table}
```
\subsection{Comunalidades}

En el análisis de componentes principales, las comunalidades son los elementos diagonales de la matriz analizada (la matriz de correlaciones o covarianza); en el análisis factorial, son las sumas de los cuadrados de las saturaciones para cada variable, utilizando todas las otras variables como predictores (ver Tabla 5). Esto indica, en el caso de la matriz de correlaciones, que la comunalidad es el porcentaje de varianza explicado por los componentes principales de la variable original determinada. Por ejemplo, para HPM, se observa que los tres componentes elegidos explican aproximadamente el 79,87% de la variabilidad; sin embargo, el porcentaje correspondiente al componente uno es de 83% frente al 16% y 0.3% en los componentes 2 y 3 respectivamente. Igual comportamiento se observa en las demás variables, excepto con NHS (número de horas semanales de los centros de alimentación en funcionamiento). Teniendo en cuenta estos porcentajes, podemos afirmar que todas las variables pueden resumirse con un solo componente principal, como se puede reconfirmar con los resultados mostrados en la Tabla 6. Para el caso en estudio, se podría pensar que el gobierno si está cumpliendo en parte con las necesidades de los desplazados, si se tiene en cuenta la alta correlación de las variables con el componente principal.

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla5.jpg}
\caption{Tabla 5}
\end{table}
```
\subsection{Autovalores y varianza explicada}

Los autovalores se relacionan con la varianza explicada y permiten determinar el número de componentes principales adecuado (ver Tabla 6). En el caso de valores tipificados, el número de componentes principales está dado por aquellos autovalores mayores que uno. En este caso, solamente habría un solo componente principal correspondiente a lambda (λ1 = 4,597); sin embargo, para el caso se trabajará con tres componentes. Los valores de porcentaje de la varianza se estiman a partir del cociente entre λj y la traza de la matriz de R.

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla6.jpg}
\caption{Tabla 6}
\end{table}
```
La Figura 6 permite ver con mayor claridad los datos estimados en la tabla anterior.

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen8.jpg}
\caption{Figura 8}
\end{figure}
```
En la Tabla 7 se muestra la matriz de componentes C y la matriz de coeficientes de evaluación que permiten estimar los componentes principales.

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla7.jpg}
\caption{Tabla 7}
\end{table}
```
Las Tablas 8, 9 y 10 muestran los procesos para determinar las coordenadas de los sitios en nuevo sistema de componentes principales mediante los datos estimados anteriormente y haciendo uso de las siguientes fórmulas o relaciones.

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen9.jpg}
\caption{Figura 9}
\end{figure}
```
Donde *r* = 1,2,..., n ; *j* = 1,2,...

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla8.jpg}
\caption{Tabla 8}
\end{table}
```
La Tabla 8 se puede representar la matriz normalizada de los datos originales consignados en la Tabla 1 que se utiliza para el cálculo de las coordenadas de los sitios en el nuevo sistema de ejes (componentes principales). El cálculo de las coordenadas se hace a través de la matriz de autovectores que se presenta a continuación.

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla9.jpg}
\caption{Tabla 9}
\end{table}
```
En la Tabla 10 se presentan los valores de los componentes principales en el nuevo espacio generado por los tres componentes principales. Básicamente, se muestra que los datos se han reducido de un espacio de siete dimensiones a tres, lo que facilita la interpretación del problema.

```{=tex}
\begin{table}[H]
\includegraphics[]{tabla10.jpg}
\caption{Tabla 10}
\end{table}
```
```{=tex}
\begin{table}[H]
\includegraphics[]{tabla11.jpg}
\caption{Tabla 11}
\end{table}
```
La Tabla 10 muestra los valores de coordenadas de los sitios en los componentes principales que fueron estimados. En dicha tabla aparecen en negrilla las coordenadas absolutas mayores de cada sitio asociado con cada componente. Al asignar cada sitio a un componente siguiendo este criterio (ver [Tabla 11](http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0122-34612008000100010#t11) ), nuestro modelo será como se muestra a continuación:

```{=tex}
\begin{figure}[H]
\includegraphics[]{imagen10.jpg}
\caption{Figura 10}
\end{figure}
```
Siendo *r* = 1,....., 25. Las otras dos columnas se estiman de igual forma utilizando como coeficientes los valores de las columnas dos y tres de la matriz de autovectores.

\section{Conclusiones}

La aplicación del análisis de datos multivariado, específicamente de la técnica de componentes principales, al caso de los desplazados de un municipio de Colombia permite sacar las siguientes conclusiones:

Las siete variables originales estudiadas en el caso de los desplazados quedan resumidas en tres índices (componentes principales), que están explicando el 87,542% de la variabilidad total (ver Tabla 7).

Según la matriz de autovectores, el primer componente principal asocia las variables NPM, CCD y NTC, explicando un 65,675% de la variabilidad total, equivalente al 75% del total explicado por los tres componentes (ver Tablas 7 y 10 ).

Al segundo componente principal le corresponden las variables HPM, ATR y NBC, explicando el 12,267% de la variabilidad total, equivalente al 14% del total explicado por los tres componentes, ver tablas 7 y 10.

Al tercer componente principal le corresponde la variable NHS, explicando el 9,6% de la variabilidad total, equivalente al 11% del total explicado por los tres componentes (ver Tablas 7 y 10 ).

Analizando las variables por componentes se pueden evidenciar los siguientes aspectos (recordar que por ser un caso, las conclusiones sólo hacen referencia a los datos seleccionados):

Según los resultados de la Tabla 10 de autovectores, el componente 1 al asociar con más peso las variables NPM, CCD y NTC se puede definir como el índice que mide la atención que el gobierno local ofrece a los desplazados. Sin embargo, creemos que no son suficientes las acciones realizadas por el gobierno local y nacional dado que para la movilidad de los desplazados hay poca disponibilidad de camas y cuartos. Hay que anotar que sólo en algunos sitios se percibe que el gobierno cumple a cabalidad el compromiso adquirido con la sociedad. Por ejemplo, los sitios 22, 23 y 24.

En el componente 2, las horas promedio de movilidad diaria (HPM), que al compararlo con las áreas totales de recreación de uso común (ATR) y números centros de lugar de posible concentración (NBC), explica en gran parte el interés del gobierno por concentrar a los desplazados en lugares determinados proporcionándoles áreas de recreación común. Esto se puede evidenciar en los sitios 9, 22 y 23, donde las áreas recreacionales y/o de concentración responden a la movilidad de los desplazados más adecuadamente que los demás sitios.

El componente 3 se puede definir como el índice de atención alimentaria de los desplazados. El número de horas semanales en que los centros de alimentación están funcionando, parece no ser suficiente para atender al personal que se presenta en los diferentes sitios.
